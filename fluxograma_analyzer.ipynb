{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreGuerra-prod/_ENAP/blob/main/fluxograma_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install transformers\n",
        "!pip install networkx\n",
        "!pip install matplotlib\n",
        "!sudo apt update\n",
        "!sudo apt install tesseract-ocr\n"
      ],
      "metadata": {
        "id": "cwXaOy67_BTl"
      },
      "id": "cwXaOy67_BTl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "id": "fEvDmUfT_IpT"
      },
      "id": "fEvDmUfT_IpT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importações e Setup\n",
        "import pytesseract\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import networkx as nx\n",
        "import os\n",
        "!pip install fpdf\n",
        "from fpdf import FPDF"
      ],
      "metadata": {
        "id": "JL4VqYMS_aIN"
      },
      "id": "JL4VqYMS_aIN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. OCR - Extração de Texto com Coordenadas\n",
        "def extract_text_blocks(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    blocks = []\n",
        "    for i in range(len(data['text'])):\n",
        "        text = data['text'][i].strip()\n",
        "        if text:\n",
        "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "            blocks.append({'text': text, 'bbox': (x, y, w, h)})\n",
        "            draw.rectangle([x, y, x + w, y + h], outline='red', width=2)\n",
        "            draw.text((x, y - 10), text, fill='blue')\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Blocos de Texto Detectados\")\n",
        "    plt.show()\n",
        "    return blocks"
      ],
      "metadata": {
        "id": "7fgMfjUc_zhy"
      },
      "id": "7fgMfjUc_zhy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Análise com BLIP (modelo multimodal)\n",
        "def analyze_with_blip(image_path):\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption"
      ],
      "metadata": {
        "id": "CJrk7RBI__EK"
      },
      "id": "CJrk7RBI__EK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Construção e Análise de Grafo\n",
        "def draw_and_identify_bottlenecks(blocks):\n",
        "    G = nx.DiGraph()\n",
        "    for i, block in enumerate(blocks):\n",
        "        G.add_node(i, label=block['text'])\n",
        "        if i > 0:\n",
        "            G.add_edge(i - 1, i)\n",
        "    pos = nx.spring_layout(G)\n",
        "    labels = nx.get_node_attributes(G, 'label')\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    nx.draw(G, pos, with_labels=True, labels=labels, node_size=2000, node_color='lightblue', font_size=10)\n",
        "    bottlenecks = [n for n in G.nodes if G.in_degree(n) > 1]\n",
        "    nx.draw_networkx_nodes(G, pos, nodelist=bottlenecks, node_color='red')\n",
        "    plt.title(\"Grafo Gerado e Gargalos (vermelho)\")\n",
        "    plt.axis('off')\n",
        "    plt.savefig(\"grafo_corrigido.png\")\n",
        "    plt.show()\n",
        "    return G, bottlenecks"
      ],
      "metadata": {
        "id": "f5PYoGLhAH-g"
      },
      "id": "f5PYoGLhAH-g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Sugestões de Correção para Gargalos\n",
        "def sugerir_correcao(grafo, gargalos):\n",
        "    sugestoes = []\n",
        "    for g in gargalos:\n",
        "        label = grafo.nodes[g].get('label', f'Nó {g}')\n",
        "        sugestao = f\"O bloco '{label}' é um gargalo. Sugestão: divida o fluxo de entrada ou revise a lógica de dependência.\"\n",
        "        sugestoes.append(sugestao)\n",
        "    return sugestoes"
      ],
      "metadata": {
        "id": "XEGofcq_AK6g"
      },
      "id": "XEGofcq_AK6g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Gerar PDF da imagem corrigida\n",
        "def gerar_pdf(imagem_path, sugestoes):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=\"Fluxograma Corrigido\", ln=True, align='C')\n",
        "    pdf.image(imagem_path, x=10, y=30, w=190)\n",
        "    pdf.ln(120)\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.cell(200, 10, txt=\"Sugestões de Correção:\", ln=True)\n",
        "    for s in sugestoes:\n",
        "        pdf.multi_cell(0, 8, txt=\"- \" + s)\n",
        "    pdf.output(\"fluxograma_corrigido.pdf\")"
      ],
      "metadata": {
        "id": "dR1pkOIeAU7I"
      },
      "id": "dR1pkOIeAU7I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Certifica-se de que o diretório 'imagens' existe\n",
        "import os\n",
        "if not os.path.exists(\"imagens\"):\n",
        "    os.makedirs(\"imagens\")\n",
        "    print(\"Diretório 'imagens' criado.\")\n",
        "\n",
        "# URL RAW da imagem no seu repositório GitHub\n",
        "image_url = \"https://raw.githubusercontent.com/AlexandreGuerra-prod/_ENAP/main/exemplo_fluxograma.png\"\n",
        "# Caminho onde a imagem será salva localmente\n",
        "local_image_path = \"imagens/exemplo_fluxograma.png\"\n",
        "\n",
        "# Baixa a imagem do GitHub para o caminho local usando wget\n",
        "# O -O especifica o nome do arquivo de saída local\n",
        "!wget -O {local_image_path} {image_url}\n",
        "\n",
        "print(f\"Imagem baixada para: {local_image_path}\")\n",
        "\n",
        "# Agora, use o caminho local da imagem na execução do seu código\n",
        "image_path = local_image_path\n",
        "\n",
        "# 7. Execução Exemplo (seu código original continua aqui)\n",
        "blocks = extract_text_blocks(image_path)\n",
        "caption = analyze_with_blip(image_path)\n",
        "print(\"Descrição:\", caption)\n",
        "G, bottlenecks = draw_and_identify_bottlenecks(blocks)\n",
        "sugestoes = sugerir_correcao(G, bottlenecks)\n",
        "gerar_pdf(\"grafo_corrigido.png\", sugestoes)"
      ],
      "metadata": {
        "id": "jPt5nguWAemH"
      },
      "id": "jPt5nguWAemH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D1Ck5F-oAgA7"
      },
      "id": "D1Ck5F-oAgA7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Análise com BLIP (modelo multimodal)\n",
        "def analyze_with_blip(image_path):\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption"
      ],
      "metadata": {
        "id": "ej2AvIgVEQAV"
      },
      "id": "ej2AvIgVEQAV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}