{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreGuerra-prod/_ENAP/blob/main/fluxograma_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importações e Setup\n",
        "import pytesseract  # Biblioteca para OCR (Reconhecimento Óptico de Caracteres)\n",
        "from PIL import Image, ImageDraw  # Biblioteca para manipulação de imagens\n",
        "import matplotlib.pyplot as plt  # Biblioteca para criação de gráficos\n",
        "import torch  # Biblioteca para operações de Tensor, necessária para modelos de ML\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration  # Para processamento e geração de legendas\n",
        "import networkx as nx  # Biblioteca para manipulação de grafos\n",
        "import os  # Biblioteca para interações com o sistema operacional\n",
        "from fpdf import FPDF  # Biblioteca para gerar arquivos PDF\n",
        "\n",
        "# 2. Função para Extração de Texto com OCR - Pytesseract\n",
        "def extract_text_blocks(image_path):\n",
        "    \"\"\"\n",
        "    Esta função extrai blocos de texto de uma imagem utilizando OCR e retorna suas coordenadas.\n",
        "\n",
        "    :param image_path: Caminho para a imagem de entrada.\n",
        "    :return: Lista de blocos de texto com informações de coordenadas.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Abre a imagem e a converte para RGB\n",
        "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)  # Realiza OCR\n",
        "    draw = ImageDraw.Draw(image)  # Cria um objeto para desenhar na imagem\n",
        "    blocks = []  # Lista para armazenar os blocos de texto\n",
        "\n",
        "    # Percorre cada item retornado pelo OCR\n",
        "    for i in range(len(data['text'])):\n",
        "        text = data['text'][i].strip()  # Remove espaços em branco\n",
        "        if text:  # Verifica se o texto não está vazio\n",
        "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "            blocks.append({\n",
        "                'text': text,  # Texto extraído\n",
        "                'bbox': (x, y, w, h)  # Caixa delimitadora: posição e tamanho\n",
        "            })\n",
        "            # Desenha um retângulo na imagem ao redor do texto\n",
        "            draw.rectangle([x, y, x + w, y + h], outline='red', width=2)\n",
        "            draw.text((x, y - 10), text, fill='blue')  # Adiciona o texto acima do retângulo\n",
        "\n",
        "    # Exibe a imagem com os blocos de texto destacados\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Remove os eixos\n",
        "    plt.title(\"Blocos de Texto Detectados\")\n",
        "    plt.show()\n",
        "\n",
        "    return blocks  # Retorna a lista de blocos de texto\n",
        "\n",
        "\n",
        "# 3. Análise com BLIP (Modelo Multimodal de Imagem)\n",
        "def analyze_with_blip(image_path):\n",
        "    \"\"\"\n",
        "    Esta função gera uma descrição para a imagem usando um modelo de linguagem e visão (BLIP).\n",
        "\n",
        "    :param image_path: Caminho para a imagem de entrada.\n",
        "    :return: Descrição da imagem gerada pelo modelo.\n",
        "    \"\"\"\n",
        "    # Inicializa o processador e o modelo BLIP\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Abre a imagem\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")  # Processa a imagem para tensor\n",
        "    out = model.generate(**inputs)  # Gera a descrição\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)  # Decodifica a saída\n",
        "    return caption  # Retorna a descrição\n",
        "\n",
        "\n",
        "# 4. Construção e Análise de Grafo\n",
        "def draw_and_identify_bottlenecks(blocks):\n",
        "    \"\"\"\n",
        "    Esta função cria um grafo a partir dos blocos de texto e identifica gargalos.\n",
        "\n",
        "    :param blocks: Lista de blocos de texto.\n",
        "    :return: Tupla (grafo, lista de gargalos).\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()  # Cria um grafo direcionado\n",
        "    for i, block in enumerate(blocks):\n",
        "        G.add_node(i, label=block['text'])  # Adiciona nó para cada bloco de texto\n",
        "        if i > 0:\n",
        "            G.add_edge(i - 1, i)  # Cria uma ligação entre blocos sequenciais\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Calcula a posição dos nós no grafo\n",
        "    labels = nx.get_node_attributes(G, 'label')  # Obtém rótulos para os nós\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    nx.draw(G, pos, with_labels=True, labels=labels, node_size=2000, node_color='lightblue', font_size=10)\n",
        "\n",
        "    # Identifica gargalos: nós com alto grau de entrada\n",
        "    bottlenecks = [n for n in G.nodes if G.in_degree(n) > 1]  # Nós que recebem entrada de múltiplos nós\n",
        "    nx.draw_networkx_nodes(G, pos, nodelist=bottlenecks, node_color='red')  # Destaca os gargalos em vermelho\n",
        "    plt.title(\"Grafo Gerado e Gargalos (vermelho)\")\n",
        "    plt.axis('off')  # Remove os eixos\n",
        "    plt.savefig(\"grafo_corrigido.png\")  # Salva a imagem do grafo\n",
        "    plt.show()\n",
        "    return G, bottlenecks  # Retorna o grafo e os gargalos\n",
        "\n",
        "\n",
        "# 5. Sugestões para Correção de Gargalos\n",
        "def sugerir_correcao(grafo, gargalos):\n",
        "    \"\"\"\n",
        "    Esta função gera sugestões para melhorar os gargalos detectados no grafo.\n",
        "\n",
        "    :param grafo: O grafo analisado.\n",
        "    :param gargalos: Lista de nós que são gargalos.\n",
        "    :return: Lista de sugestões.\n",
        "    \"\"\"\n",
        "    sugestoes = []  # Lista para armazenar sugestões\n",
        "    for g in gargalos:\n",
        "        label = grafo.nodes[g].get('label', f'Nó {g}')  # Obtém a etiqueta do nó, se disponível\n",
        "        sugestao = f\"O bloco '{label}' é um gargalo. Sugestão: divida o fluxo de entrada ou revise a lógica de dependência.\"\n",
        "        sugestoes.append(sugestao)  # Adiciona a sugestão à lista\n",
        "    return sugestoes  # Retorna a lista de sugestões\n",
        "\n",
        "\n",
        "# 6. Gerar PDF da Imagem Corrigida\n",
        "def gerar_pdf(imagem_path, sugestoes):\n",
        "    \"\"\"\n",
        "    Esta função gera um PDF com a imagem do fluxograma e as sugestões de correção.\n",
        "\n",
        "    :param imagem_path: Caminho para a imagem do grafo.\n",
        "    :param sugestoes: Lista de sugestões para correção.\n",
        "    \"\"\"\n",
        "    pdf = FPDF()  # Cria uma instância do PDF\n",
        "    pdf.add_page()  # Adiciona uma página ao PDF\n",
        "    pdf.set_font(\"Arial\", size=12)  # Define a fonte e tamanho\n",
        "    pdf.cell(200, 10, txt=\"Fluxograma Corrigido\", ln=True, align='C')  # Título do PDF\n",
        "    pdf.image(imagem_path, x=10, y=30, w=190)  # Adiciona a imagem do grafo ao PDF\n",
        "    pdf.ln(120)  # Espaçamento\n",
        "    pdf.set_font(\"Arial\", size=10)  # Define a fonte para sugestões\n",
        "    pdf.cell(200, 10, txt=\"Sugestões de Correção:\", ln=True)  # Título das sugestões\n",
        "    for s in sugestoes:\n",
        "        pdf.multi_cell(0, 8, txt=\"- \" + s)  # Adiciona cada sugestão como uma nova linha\n",
        "    pdf.output(\"fluxograma_corrigido.pdf\")  # Salva o PDF com o nome especificado\n",
        "\n",
        "\n",
        "# 7. Execução Exemplo do Pipeline Completo\n",
        "# Certifica-se de que o diretório 'imagens' existe\n",
        "if not os.path.exists(\"imagens\"):\n",
        "    os.makedirs(\"imagens\")  # Cria o diretório se não existir\n",
        "    print(\"Diretório 'imagens' criado.\")\n",
        "\n",
        "# URL RAW da imagem no seu repositório GitHub\n",
        "image_url = \"https://raw.githubusercontent.com/AlexandreGuerra-prod/_ENAP/main/exemplo_fluxograma.png\"\n",
        "local_image_path = \"imagens/exemplo_fluxograma.png\"  # Caminho onde a imagem será salva localmente\n",
        "\n",
        "# Baixa a imagem do GitHub para o caminho local usando wget\n",
        "!wget -O {local_image_path} {image_url}  # O -O especifica o nome do arquivo de saída local\n",
        "\n",
        "print(f\"Imagem baixada para: {local_image_path}\")\n",
        "\n",
        "# Execução das funções\n",
        "image_path = local_image_path  # Usa o caminho local da imagem\n",
        "\n",
        "# 7. Executando as etapas do pipeline\n",
        "blocks = extract_text_blocks(image_path)  # Extração dos blocos de texto\n",
        "caption = analyze_with_blip(image_path)  # Análise multimodal com BLIP\n",
        "print(\"Descrição:\", caption)  # Exibe a descrição gerada pela BLIP\n",
        "G, bottlenecks = draw_and_identify_bottlenecks(blocks)  # Geração do grafo e identificação de gargalos\n",
        "sugestoes = sugerir_correcao(G, bottlenecks)  # Sugestões para correções\n",
        "gerar_pdf(\"grafo_corrigido.png\", sugestoes)  # Gera o PDF com as sugestões\n",
        "\n",
        "# Mensagens de log para o usuário\n",
        "print(\"\\n🔍 Executando OCR e extração de blocos:\")\n",
        "blocks = extract_text_blocks(image_path)\n",
        "\n",
        "print(\"\\n🧠 Análise multimodal com BLIP:\")\n",
        "caption = analyze_with_blip(image_path)\n",
        "print(\"\\nDescrição do Diagrama:\", caption)\n",
        "\n",
        "print(\"\\n🔗 Construção do grafo e identificação de gargalos:\")\n",
        "G, bottlenecks = draw_and_identify_bottlenecks(blocks)\n",
        "print(\"\\nGargalos detectados nos nós:\", bottlenecks)\n",
        "\n",
        "print(\"\\n🛠 Sugestões de melhoria:\")\n",
        "sugestoes = sugerir_correcao(G, bottlenecks)\n",
        "for s in sugestoes:\n",
        "    print(\"-\", s)\n",
        "\n",
        "print(\"\\n📄 Exportando grafo corrigido para PDF...\")\n",
        "gerar_pdf(\"grafo_corrigido.png\", sugestoes)\n",
        "print(\"PDF salvo como 'fluxograma_corrigido.pdf'\")"
      ],
      "metadata": {
        "id": "TCZHWLPnYWOC"
      },
      "id": "TCZHWLPnYWOC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}