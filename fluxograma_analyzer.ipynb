{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreGuerra-prod/_ENAP/blob/main/fluxograma_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importa√ß√µes e Setup\n",
        "import pytesseract  # Biblioteca para OCR (Reconhecimento √ìptico de Caracteres)\n",
        "from PIL import Image, ImageDraw  # Biblioteca para manipula√ß√£o de imagens\n",
        "import matplotlib.pyplot as plt  # Biblioteca para cria√ß√£o de gr√°ficos\n",
        "import torch  # Biblioteca para opera√ß√µes de Tensor, necess√°ria para modelos de ML\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration  # Para processamento e gera√ß√£o de legendas\n",
        "import networkx as nx  # Biblioteca para manipula√ß√£o de grafos\n",
        "import os  # Biblioteca para intera√ß√µes com o sistema operacional\n",
        "from fpdf import FPDF  # Biblioteca para gerar arquivos PDF\n",
        "\n",
        "# 2. Fun√ß√£o para Extra√ß√£o de Texto com OCR - Pytesseract\n",
        "def extract_text_blocks(image_path):\n",
        "    \"\"\"\n",
        "    Esta fun√ß√£o extrai blocos de texto de uma imagem utilizando OCR e retorna suas coordenadas.\n",
        "\n",
        "    :param image_path: Caminho para a imagem de entrada.\n",
        "    :return: Lista de blocos de texto com informa√ß√µes de coordenadas.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Abre a imagem e a converte para RGB\n",
        "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)  # Realiza OCR\n",
        "    draw = ImageDraw.Draw(image)  # Cria um objeto para desenhar na imagem\n",
        "    blocks = []  # Lista para armazenar os blocos de texto\n",
        "\n",
        "    # Percorre cada item retornado pelo OCR\n",
        "    for i in range(len(data['text'])):\n",
        "        text = data['text'][i].strip()  # Remove espa√ßos em branco\n",
        "        if text:  # Verifica se o texto n√£o est√° vazio\n",
        "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "            blocks.append({\n",
        "                'text': text,  # Texto extra√≠do\n",
        "                'bbox': (x, y, w, h)  # Caixa delimitadora: posi√ß√£o e tamanho\n",
        "            })\n",
        "            # Desenha um ret√¢ngulo na imagem ao redor do texto\n",
        "            draw.rectangle([x, y, x + w, y + h], outline='red', width=2)\n",
        "            draw.text((x, y - 10), text, fill='blue')  # Adiciona o texto acima do ret√¢ngulo\n",
        "\n",
        "    # Exibe a imagem com os blocos de texto destacados\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Remove os eixos\n",
        "    plt.title(\"Blocos de Texto Detectados\")\n",
        "    plt.show()\n",
        "\n",
        "    return blocks  # Retorna a lista de blocos de texto\n",
        "\n",
        "\n",
        "# 3. An√°lise com BLIP (Modelo Multimodal de Imagem)\n",
        "def analyze_with_blip(image_path):\n",
        "    \"\"\"\n",
        "    Esta fun√ß√£o gera uma descri√ß√£o para a imagem usando um modelo de linguagem e vis√£o (BLIP).\n",
        "\n",
        "    :param image_path: Caminho para a imagem de entrada.\n",
        "    :return: Descri√ß√£o da imagem gerada pelo modelo.\n",
        "    \"\"\"\n",
        "    # Inicializa o processador e o modelo BLIP\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Abre a imagem\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")  # Processa a imagem para tensor\n",
        "    out = model.generate(**inputs)  # Gera a descri√ß√£o\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)  # Decodifica a sa√≠da\n",
        "    return caption  # Retorna a descri√ß√£o\n",
        "\n",
        "\n",
        "# 4. Constru√ß√£o e An√°lise de Grafo\n",
        "def draw_and_identify_bottlenecks(blocks):\n",
        "    \"\"\"\n",
        "    Esta fun√ß√£o cria um grafo a partir dos blocos de texto e identifica gargalos.\n",
        "\n",
        "    :param blocks: Lista de blocos de texto.\n",
        "    :return: Tupla (grafo, lista de gargalos).\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()  # Cria um grafo direcionado\n",
        "    for i, block in enumerate(blocks):\n",
        "        G.add_node(i, label=block['text'])  # Adiciona n√≥ para cada bloco de texto\n",
        "        if i > 0:\n",
        "            G.add_edge(i - 1, i)  # Cria uma liga√ß√£o entre blocos sequenciais\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Calcula a posi√ß√£o dos n√≥s no grafo\n",
        "    labels = nx.get_node_attributes(G, 'label')  # Obt√©m r√≥tulos para os n√≥s\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    nx.draw(G, pos, with_labels=True, labels=labels, node_size=2000, node_color='lightblue', font_size=10)\n",
        "\n",
        "    # Identifica gargalos: n√≥s com alto grau de entrada\n",
        "    bottlenecks = [n for n in G.nodes if G.in_degree(n) > 1]  # N√≥s que recebem entrada de m√∫ltiplos n√≥s\n",
        "    nx.draw_networkx_nodes(G, pos, nodelist=bottlenecks, node_color='red')  # Destaca os gargalos em vermelho\n",
        "    plt.title(\"Grafo Gerado e Gargalos (vermelho)\")\n",
        "    plt.axis('off')  # Remove os eixos\n",
        "    plt.savefig(\"grafo_corrigido.png\")  # Salva a imagem do grafo\n",
        "    plt.show()\n",
        "    return G, bottlenecks  # Retorna o grafo e os gargalos\n",
        "\n",
        "\n",
        "# 5. Sugest√µes para Corre√ß√£o de Gargalos\n",
        "def sugerir_correcao(grafo, gargalos):\n",
        "    \"\"\"\n",
        "    Esta fun√ß√£o gera sugest√µes para melhorar os gargalos detectados no grafo.\n",
        "\n",
        "    :param grafo: O grafo analisado.\n",
        "    :param gargalos: Lista de n√≥s que s√£o gargalos.\n",
        "    :return: Lista de sugest√µes.\n",
        "    \"\"\"\n",
        "    sugestoes = []  # Lista para armazenar sugest√µes\n",
        "    for g in gargalos:\n",
        "        label = grafo.nodes[g].get('label', f'N√≥ {g}')  # Obt√©m a etiqueta do n√≥, se dispon√≠vel\n",
        "        sugestao = f\"O bloco '{label}' √© um gargalo. Sugest√£o: divida o fluxo de entrada ou revise a l√≥gica de depend√™ncia.\"\n",
        "        sugestoes.append(sugestao)  # Adiciona a sugest√£o √† lista\n",
        "    return sugestoes  # Retorna a lista de sugest√µes\n",
        "\n",
        "\n",
        "# 6. Gerar PDF da Imagem Corrigida\n",
        "def gerar_pdf(imagem_path, sugestoes):\n",
        "    \"\"\"\n",
        "    Esta fun√ß√£o gera um PDF com a imagem do fluxograma e as sugest√µes de corre√ß√£o.\n",
        "\n",
        "    :param imagem_path: Caminho para a imagem do grafo.\n",
        "    :param sugestoes: Lista de sugest√µes para corre√ß√£o.\n",
        "    \"\"\"\n",
        "    pdf = FPDF()  # Cria uma inst√¢ncia do PDF\n",
        "    pdf.add_page()  # Adiciona uma p√°gina ao PDF\n",
        "    pdf.set_font(\"Arial\", size=12)  # Define a fonte e tamanho\n",
        "    pdf.cell(200, 10, txt=\"Fluxograma Corrigido\", ln=True, align='C')  # T√≠tulo do PDF\n",
        "    pdf.image(imagem_path, x=10, y=30, w=190)  # Adiciona a imagem do grafo ao PDF\n",
        "    pdf.ln(120)  # Espa√ßamento\n",
        "    pdf.set_font(\"Arial\", size=10)  # Define a fonte para sugest√µes\n",
        "    pdf.cell(200, 10, txt=\"Sugest√µes de Corre√ß√£o:\", ln=True)  # T√≠tulo das sugest√µes\n",
        "    for s in sugestoes:\n",
        "        pdf.multi_cell(0, 8, txt=\"- \" + s)  # Adiciona cada sugest√£o como uma nova linha\n",
        "    pdf.output(\"fluxograma_corrigido.pdf\")  # Salva o PDF com o nome especificado\n",
        "\n",
        "\n",
        "# 7. Execu√ß√£o Exemplo do Pipeline Completo\n",
        "# Certifica-se de que o diret√≥rio 'imagens' existe\n",
        "if not os.path.exists(\"imagens\"):\n",
        "    os.makedirs(\"imagens\")  # Cria o diret√≥rio se n√£o existir\n",
        "    print(\"Diret√≥rio 'imagens' criado.\")\n",
        "\n",
        "# URL RAW da imagem no seu reposit√≥rio GitHub\n",
        "image_url = \"https://raw.githubusercontent.com/AlexandreGuerra-prod/_ENAP/main/exemplo_fluxograma.png\"\n",
        "local_image_path = \"imagens/exemplo_fluxograma.png\"  # Caminho onde a imagem ser√° salva localmente\n",
        "\n",
        "# Baixa a imagem do GitHub para o caminho local usando wget\n",
        "!wget -O {local_image_path} {image_url}  # O -O especifica o nome do arquivo de sa√≠da local\n",
        "\n",
        "print(f\"Imagem baixada para: {local_image_path}\")\n",
        "\n",
        "# Execu√ß√£o das fun√ß√µes\n",
        "image_path = local_image_path  # Usa o caminho local da imagem\n",
        "\n",
        "# 7. Executando as etapas do pipeline\n",
        "blocks = extract_text_blocks(image_path)  # Extra√ß√£o dos blocos de texto\n",
        "caption = analyze_with_blip(image_path)  # An√°lise multimodal com BLIP\n",
        "print(\"Descri√ß√£o:\", caption)  # Exibe a descri√ß√£o gerada pela BLIP\n",
        "G, bottlenecks = draw_and_identify_bottlenecks(blocks)  # Gera√ß√£o do grafo e identifica√ß√£o de gargalos\n",
        "sugestoes = sugerir_correcao(G, bottlenecks)  # Sugest√µes para corre√ß√µes\n",
        "gerar_pdf(\"grafo_corrigido.png\", sugestoes)  # Gera o PDF com as sugest√µes\n",
        "\n",
        "# Mensagens de log para o usu√°rio\n",
        "print(\"\\nüîç Executando OCR e extra√ß√£o de blocos:\")\n",
        "blocks = extract_text_blocks(image_path)\n",
        "\n",
        "print(\"\\nüß† An√°lise multimodal com BLIP:\")\n",
        "caption = analyze_with_blip(image_path)\n",
        "print(\"\\nDescri√ß√£o do Diagrama:\", caption)\n",
        "\n",
        "print(\"\\nüîó Constru√ß√£o do grafo e identifica√ß√£o de gargalos:\")\n",
        "G, bottlenecks = draw_and_identify_bottlenecks(blocks)\n",
        "print(\"\\nGargalos detectados nos n√≥s:\", bottlenecks)\n",
        "\n",
        "print(\"\\nüõ† Sugest√µes de melhoria:\")\n",
        "sugestoes = sugerir_correcao(G, bottlenecks)\n",
        "for s in sugestoes:\n",
        "    print(\"-\", s)\n",
        "\n",
        "print(\"\\nüìÑ Exportando grafo corrigido para PDF...\")\n",
        "gerar_pdf(\"grafo_corrigido.png\", sugestoes)\n",
        "print(\"PDF salvo como 'fluxograma_corrigido.pdf'\")"
      ],
      "metadata": {
        "id": "TCZHWLPnYWOC"
      },
      "id": "TCZHWLPnYWOC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}